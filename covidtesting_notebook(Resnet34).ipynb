{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covidtesting_notebook(Resnet34).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajsanjoaquin/COVID-19-Scanner/blob/master/covidtesting_notebook(Resnet34).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syNJC42pUjl9"
      },
      "source": [
        "#COVID-19 Diagnosis Triage Tool\n",
        "\n",
        "This model is meant to identify priority patients to receive medical attention, particularly testing for COVID-19, based on their X-ray images scans and risk factors contained in the DICOM metadata.\n",
        "\n",
        "This model is provided as-is, and not meant to diagnose  COVID-19. This model has no clinical approval, nor endorsements from any health organizations. At the moment, this model is for research and testing purposes. In no way is the author responsible for any damages resulting from using this model. \n",
        "\n",
        "Contact: [Ayrton San Joaquin](mailto:ayrton@u.yale-nus.edu.sg)\n",
        "\n",
        "License: MIT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fDTcYzSMDucn"
      },
      "source": [
        "#PURE PYTORCH IMPLEMENTATION\n",
        "\n",
        "Convert DICOM Images to png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42fHouwi_inJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydicom pypng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxNnBs9pUC2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchvision\n",
        "import logging as log\n",
        "from typing import Optional # required for \"Optional[type]\"\n",
        "import os,re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import pydicom\n",
        "import png\n",
        "\n",
        "#put test images in test folder\n",
        "if not os.path.isdir('test'):\n",
        "  os.makedirs('test')\n",
        "\n",
        "path_to_test='test/'\n",
        "\n",
        "def get_metadata(folder,filename, attribute):\n",
        "    '''\n",
        "    Given a path to folder of images, patient ID, and attribute, return useful meta-data from the corresponding dicom image.\n",
        "    IMPLICITLY Converts dicom image to png in the process and puts to test folder\n",
        "    Return: \n",
        "    attribute value, png image (implicit)\n",
        "    '''\n",
        "    ds=pydicom.dcmread(folder+'/'+filename+'.dcm')\n",
        "\n",
        "    #implicit DICOM -> PNG conversion\n",
        "    shape = ds.pixel_array.shape\n",
        "    # Convert to float to avoid overflow or underflow losses.\n",
        "    image_2d = ds.pixel_array.astype(float)\n",
        "    # Rescaling grey scale between 0-255\n",
        "    image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
        "    # Convert to uint\n",
        "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
        "    # Write the PNG file\n",
        "    with open(os.path.join(folder,filename+'.png'), 'wb') as png_file:\n",
        "        w = png.Writer(shape[1], shape[0], greyscale=True)\n",
        "        w.write(png_file, image_2d_scaled)\n",
        "    try: \n",
        "      attribute_value = getattr(ds, attribute)\n",
        "      return attribute_value\n",
        "    except: return np.NaN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCLxeAC_vcx",
        "colab_type": "text"
      },
      "source": [
        "###Upload your files before running the code blocks below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3WH4Cf_KXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of files to be converted\n",
        "files = [f[:-4] for f in os.listdir(path_to_test) if f.endswith('.dcm')]\n",
        "result_df=pd.DataFrame(files,columns=['filename'])\n",
        "\n",
        "#list of essential attributes\n",
        "attributes = ['PatientID','PatientSex', 'PatientAge', 'ViewPosition']\n",
        "for a in attributes:\n",
        "    result_df[a] = result_df['filename'].apply(lambda x: get_metadata(path_to_test, x, a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2fHP3RFUloh",
        "colab_type": "text"
      },
      "source": [
        "##Model Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kxVuivn32TCY",
        "colab": {}
      },
      "source": [
        "#download model\n",
        "!wget -O corona_resnet34.pth https://www.dropbox.com/s/o27w0dik8hdjaab/corona_resnet34.pth?dl=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GZHgM1-Z8Oqb",
        "colab": {}
      },
      "source": [
        "#Code taken from Andrea de Luca (https://bit.ly/2YXW6xN)\n",
        "## The code below gives you Flatten and the double Adaptive Pooling (from fastai), plus\n",
        "## a viable head. You must fill the number of FC's nodes manually through the myhead function\n",
        "\n",
        "#CPU for inference\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n",
        "    def __init__(self, full:bool=False):\n",
        "        super().__init__()\n",
        "        self.full = full\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(-1) if self.full else x.view(x.size(0), -1)\n",
        "\n",
        "class AdaptiveConcatPool2d(nn.Module):\n",
        "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\" # from pytorch\n",
        "    def __init__(self, sz:Optional[int]=None): \n",
        "        \"Output will be 2*sz or 2 if sz is None\"\n",
        "        super().__init__()\n",
        "        self.output_size = sz or 1\n",
        "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
        "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
        "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
        "    \n",
        "def myhead(nf, nc):\n",
        "    '''\n",
        "    Inputs: nf=  # of in_features in the 4th layer , nc= # of classes\n",
        "    '''\n",
        "    return \\\n",
        "    nn.Sequential(        # the dropout is needed otherwise you cannot load the weights\n",
        "            AdaptiveConcatPool2d(),\n",
        "            Flatten(),\n",
        "            nn.BatchNorm1d(nf,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True),\n",
        "            nn.Dropout(p=0.25,inplace=False),\n",
        "            nn.Linear(nf, 512,bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(512,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True),\n",
        "            nn.Dropout(p=0.5,inplace=False),\n",
        "            nn.Linear(512, nc,bias=True),\n",
        "        )\n",
        "\n",
        "\n",
        "my_model=torchvision.models.resnet34() \n",
        "modules=list(my_model.children())\n",
        "modules.pop(-1) \n",
        "modules.pop(-1) \n",
        "temp=nn.Sequential(nn.Sequential(*modules))\n",
        "tempchildren=list(temp.children()) \n",
        "\n",
        "#append the special fastai head\n",
        "#Configured according to Model Architecture\n",
        "\n",
        "tempchildren.append(myhead(1024,3))\n",
        "model_r34=nn.Sequential(*tempchildren)\n",
        "\n",
        "#LOAD MODEL\n",
        "state = torch.load('corona_resnet34.pth',map_location=torch.device('cpu'))\n",
        "model_r34.load_state_dict(state['model'])\n",
        "\n",
        "\n",
        "#important to set to evaluation mode\n",
        "model_r34.eval()\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(512),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_image(model,image):\n",
        "    softmaxer = torch.nn.Softmax(dim=1)\n",
        "    image_tensor = PIL.Image.open(image)\n",
        "    image_tensor = image_tensor.convert('RGB')\n",
        "    image_tensor = test_transforms(image_tensor).float()\n",
        "    image_tensor=image_tensor.unsqueeze(0)\n",
        "\n",
        "    #convert evaluation to probabilities with softmax\n",
        "    with torch.no_grad(): #turn off backpropagation\n",
        "      processed=softmaxer(model(image_tensor))\n",
        "    return processed[0] #return probabilities\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bEe1PH4dwYix"
      },
      "source": [
        "##Before running the code below, put the test images in the test folder that was just created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K8r9AL6X_F_F",
        "colab": {}
      },
      "source": [
        "#accepts png files\n",
        "test_files=[file for file in sorted(os.listdir(path_to_test))if file.endswith('.png')]\n",
        "pytorch_results={filename:predict_image(model_r34,path_to_test+filename) for filename in test_files}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FuRl6NDtw5-o"
      },
      "source": [
        "###Results are saved in a .csv file in the colab workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7YqjQQw_STi",
        "colab": {}
      },
      "source": [
        "predictions_df=pd.DataFrame.from_dict(pytorch_results,orient='index',columns=['covid','nofinding','opacity']).rename_axis('filename').reset_index()\n",
        "predictions_df['covid']=predictions_df['covid'].apply(lambda x: x.item())\n",
        "predictions_df['nofinding']=predictions_df['nofinding'].apply(lambda x: x.item())\n",
        "predictions_df['opacity']=predictions_df['opacity'].apply(lambda x: x.item())\n",
        "\n",
        "#get the column name of the highest probability\n",
        "predictions_df['Predicted Label'] =predictions_df[['covid','opacity','nofinding']].idxmax(axis=1)\n",
        "predictions_df['filename']=predictions_df['filename'].str.slice(stop=-4) #remove .png suffix\n",
        "\n",
        "#merge result_df and final_df\n",
        "final_df=pd.merge(result_df,predictions_df[['filename','Predicted Label']], on='filename')\n",
        "\n",
        "#convert age to int to be used later\n",
        "final_df['PatientAge'] = pd.to_numeric(final_df['PatientAge'], errors='coerce')\n",
        "\n",
        "final_df.to_csv('results.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv-sGDP4RkOM",
        "colab_type": "text"
      },
      "source": [
        "##Additionally, critical data taken from the DICOM file produces a hierarchical recommendation list of patients for medical attention\n",
        "\n",
        "Currently, the 'Patient's Age' and 'View Position' have correlation with severity of COVID-19. AP view is usually meant for people who are incapacitated$^1$.\n",
        "Threshold for age being tagged for attention is at $45^2$.\n",
        "\n",
        "$^1$ https://radiopaedia.org/articles/chest-ap-erect-view-1\n",
        "$^2$ https://www.worldometers.info/coronavirus/coronavirus-age-sex-demographics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpMXlWC53-oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for priority action (usually testing) because the model predicts they exhibit COVID-19 Symptom/s \n",
        "for_testing_df=final_df[((final_df['Predicted Label']== 'opacity') | (final_df['Predicted Label']== 'covid'))]\n",
        "\n",
        "#subset of priority testing who needs immediate attention (AP is usually taken when patient is incapacitated, 50 & above are likely to be severely affected)\n",
        "critical_df=for_testing_df[(for_testing_df['ViewPosition']=='AP') | (for_testing_df['PatientAge'].astype('Int64') >= 50)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzzp7vTxKGtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save results as csv file if they exist\n",
        "if not for_testing_df.empty:\n",
        "  for_testing_df.to_csv('Priority.csv',header=True, index=False)\n",
        "if  not critical_df.empty:\n",
        "  critical_df.to_csv('Critical_priority.csv',header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}